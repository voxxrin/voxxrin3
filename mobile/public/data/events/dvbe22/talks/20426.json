{
  "summary": "Virtual threads are a game changer in the Java ecosystem, but their performance and memory impact varies depending on the algorithm and implementation.",
  "track": {
    "id": "2754",
    "title": "Java"
  },
  "speakers": [
    {
      "id": "5266",
      "companyName": "Red Hat",
      "fullName": "Mario Fusco",
      "photoUrl": "https://devoxxian-image-thumbnails.s3-eu-west-1.amazonaws.com/profile-f5f3b231-7458-4dd8-9a89-026d09935d64.jpg"
    }
  ],
  "room": {
    "title": "Room 8",
    "id": "4711"
  },
  "language": "EN",
  "format": {
    "id": "951",
    "duration": "PT50m",
    "title": "Conference"
  },
  "description": "<p>Virtual threads will be very likely the next big game changer in the Java ecosystem, allowing to have the scalability of asynchronous programming models with the simplicity of synchronous code. Their main claim is that, differently from native threads that are a costly and then scarce resource, you can create as many virtual threads as you want with known and much cheaper memory and performance impact than the native ones. But is this always true? What are the costs of scheduling thousands or even millions of virtual threads? Does the more frequent context switch have some performance implications? What about the cache misses that these context switches could potentially imply? During this talk we will try to answer these questions in a funny way, by analyzing an implementation of the traditional Conway's Game of Life based on the communicating sequential processes (CSP) model and using both virtual and native threads with different algorithms in order to compare their performances. Based on this analysis we will also try to derive some rules of thumb on when and how using virtual threads. </p><p><br></p>",
  "id": "20426",
  "title": "Game of Loom: implementation patterns and performance implications playing with virtual threads"
}