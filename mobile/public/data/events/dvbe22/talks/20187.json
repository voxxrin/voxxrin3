{
  "format": {
    "id": "954",
    "duration": "PT60m",
    "title": "BOF"
  },
  "track": {
    "title": "Data & AI",
    "id": "1252"
  },
  "language": "EN",
  "room": {
    "id": "4701",
    "title": "BOF 1"
  },
  "title": "Synthetic data for explainable AI",
  "id": "20187",
  "summary": "",
  "speakers": [
    {
      "id": "20083",
      "companyName": "Vectr.Consulting",
      "photoUrl": "https://devoxxian-image-thumbnails.s3-eu-west-1.amazonaws.com/profile-d0b384d8-d331-4bc7-a68b-3602ea758c13.jpeg",
      "fullName": "Ignaz Wanders"
    }
  ],
  "description": "<p>Machine learning and artificial intelligence are becoming more and more part of the standard IT landscape in enterprises and organisations.</p><p>Commonly, ML models are trained using labeled data from the past and applied on new data. </p><p>This practice generally works well, but has a few risky shortcomings: undetected biases in the data and previously unseen data can have unwanted side effects.</p><p>These side effects often go unnoticed until the impact of these side effects become visible. The consequences can be enormous and costly.</p><p><br></p><p>We will explain how we can use synthetic data to avoid biases and to achieve explainable AI. Humans are back in control over ML models.</p><p><br></p><p>Using synthetic data is very powerful, but of course building a representative data set is the new challenge and a new expertise field in AI technology.</p>"
}